{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN4310 - Nore Skulesson Stene - noress - Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Do not know if needed..\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "mandatory1_data\\mandatory1_data\\buildings\\0.jpg\n",
      "17034\n",
      "buildings\n",
      "forest\n",
      "glacier\n",
      "mountain\n",
      "sea\n",
      "street\n",
      "Data successfully split into Training (12034), Validation (2000), and Test (3000) sets.\n"
     ]
    }
   ],
   "source": [
    "# Set dataset directories\n",
    "DATASET_ROOT = Path(\"mandatory1_data/mandatory1_data\")\n",
    "CLASS_FOLDERS = []\n",
    "OUTPUT_ROOT = Path(\"./dataset_splits\") \n",
    "\n",
    "# Create lists to store file paths and labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "class_names = sorted([directory.name for directory in DATASET_ROOT.iterdir() if directory.is_dir()])  # Get class names\n",
    "\n",
    "# Task 1a - Splitting Data\n",
    "# Collect all image file paths and their labels\n",
    "for label, class_name in enumerate(class_names):\n",
    "    class_directory_path = DATASET_ROOT / class_name\n",
    "    files = list(class_directory_path.glob(\"*.jpg\"))\n",
    "    image_paths.extend(files)\n",
    "    labels.extend([label] * len(files))\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "image_paths = np.array(image_paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(class_names)\n",
    "print(image_paths[0])\n",
    "print(len(image_paths))\n",
    "\n",
    "for c in class_names:\n",
    "    print(c)\n",
    "\n",
    "# Defining the split sizes\n",
    "val_size = 2000  \n",
    "test_size = 3000  \n",
    "train_ratio = 1 - ((val_size + test_size) / 17034)  # Remaining percentage for training\n",
    "\n",
    "# First, split into test alone and train+val together\n",
    "train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
    "    image_paths, labels, test_size=test_size, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Spliting up train_val into train and validation\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    train_val_paths, train_val_labels, test_size=val_size, stratify=train_val_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Function to move files into new directory\n",
    "def move_files(image_paths, labels, split_name):\n",
    "    split_dir = OUTPUT_ROOT / split_name\n",
    "    split_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for class_name in class_names:\n",
    "        (split_dir / class_name).mkdir(parents=True, exist_ok=True)  # Creating class folders\n",
    "\n",
    "    for img_path, label in zip(image_paths, labels):\n",
    "        class_name = class_names[label]\n",
    "        shutil.copy(img_path, split_dir / class_name / img_path.name)  # Copying files to new location\n",
    "\n",
    "# Moving the images to new directories\n",
    "move_files(train_paths, train_labels, \"train\")\n",
    "move_files(val_paths, val_labels, \"val\")\n",
    "move_files(test_paths, test_labels, \"test\")\n",
    "\n",
    "print(f\"Data successfully split into Training ({len(train_paths)}), Validation ({len(val_paths)}), and Test ({len(test_paths)}) sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verification complete\n"
     ]
    }
   ],
   "source": [
    "# Task 1b\n",
    "# TODO ... \n",
    "def VerifySplits():\n",
    "    # Read the image paths in each split\n",
    "    train_files = {img.name for img in train_paths}\n",
    "    val_files = {img.name for img in val_paths}\n",
    "    test_files = {img.name for img in test_paths}\n",
    "\n",
    "    # Checking for overlapping files using intersection\n",
    "    train_val_overlap = train_files.intersection(val_files)\n",
    "    train_test_overlap = train_files.intersection(test_files)\n",
    "    val_test_overlap = val_files.intersection(test_files)\n",
    "\n",
    "    # Asserting no overlaps exist\n",
    "    assert not train_val_overlap, f\"Overlap found between train and val: {train_val_overlap}\"\n",
    "    assert not train_test_overlap, f\"Overlap found between train and test: {train_test_overlap}\"\n",
    "    assert not val_test_overlap, f\"Overlap found between val and test: {val_test_overlap}\"\n",
    "\n",
    "    print(\"Dataset verification complete\")\n",
    "\n",
    "VerifySplits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created. Train: 12034, Val: 2000, Test: 3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Example: Fetch a single batch of images and labels\\nimages, labels = next(iter(train_loader))\\nprint(f\"Batch shape: {images.shape}, Labels: {labels[:8]}\")  # Show first 8 labels\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1c\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataset_dir, transform=None):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "        # Get all image paths and labels\n",
    "        for class_idx, class_name in enumerate(class_names):\n",
    "            class_folder = dataset_dir / class_name\n",
    "            for img_path in class_folder.glob(\"*.jpg\"):  # Adjust if other formats exist\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(class_idx)  # Class index as label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Transforming Data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize all images to 224x224 for consistency\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor (C, H, W)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for ResNet\n",
    "])\n",
    "\n",
    "# Creating Dataloaders\n",
    "def get_dataloaders(batch_size=32, shuffle=True):\n",
    "    train_dataset = ImageDataset(OUTPUT_ROOT / \"train\", transform=transform)\n",
    "    val_dataset = ImageDataset(OUTPUT_ROOT / \"val\", transform=transform)\n",
    "    test_dataset = ImageDataset(OUTPUT_ROOT / \"test\", transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# Testing dataloaders\n",
    "train_loader, val_loader, test_loader = get_dataloaders()\n",
    "print(f\"DataLoaders created. Train: {len(train_loader.dataset)}, Val: {len(val_loader.dataset)}, Test: {len(test_loader.dataset)}\")\n",
    "\n",
    "\"\"\"\n",
    "# Example: Fetch a single batch of images and labels\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Batch shape: {images.shape}, Labels: {labels[:8]}\")  # Show first 8 labels\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Building and training the ResNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from Precode.ResNet import ResNet\n",
    "# Maybe make a Config dict, for tweaking parameters ??\n",
    "# Train data, test on validation set, optimize, check accuracy while training epochs\n",
    "\n",
    "# Initializing \n",
    "model = ResNet(img_channels=3, num_layers=18, num_classes=6)\n",
    "model.train()\n",
    "\n",
    "# Creating an instance of \"torch.optim.SGD\"\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.0001)\n",
    "\n",
    "# Creating loss function - CEL\n",
    "cel = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Checking if CUDA GPU is available and sending model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Training\n",
    "for batchImages, labels in train_loader:\n",
    "    batchImages, labels = batchImages.to(device), labels.to(device)  # Corrected variable names\n",
    "\n",
    "    optimizer.zero_grad()  # Zeroing gradients\n",
    "\n",
    "    outputs = model(batchImages)  # Forward \n",
    "    loss = cel(outputs, labels)  \n",
    "\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "# Evaluating\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Disabling gradients\n",
    "    for valImages, valLabels in val_loader:\n",
    "        valImages, valLabels = valImages.to(device), valLabels.to(device)\n",
    "        outputs = model(valImages)\n",
    "\n",
    "        # Get predicted classes\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += valLabels.size(0)\n",
    "        correct += (predicted == valLabels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bildeAnalyse venv)",
   "language": "python",
   "name": "venv-bildeanalyse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
